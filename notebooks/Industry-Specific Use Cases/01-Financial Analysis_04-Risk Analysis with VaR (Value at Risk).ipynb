{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15616cbc",
   "metadata": {},
   "source": [
    "**Financial Analysis - Risk analysis with VaR (Value at Risk) using `scipy.stats`**.\n",
    "\n",
    "Value at Risk (VaR) is a widely used metric to quantify the potential loss that could occur over a defined period for a given confidence level. For example, a 99% daily VaR of $1000 means that there is a 1% chance the portfolio could lose more than $1000 in a single day under normal market conditions.\n",
    "\n",
    "Based on [`piplist.txt`](./README.md) output, you should have `scipy` (which includes `scipy.stats`), `pandas`, and `numpy`, so we can perform this calculation.\n",
    "\n",
    "**Step 1: Generate Sample Daily Returns Data**\n",
    "\n",
    "VaR is typically calculated on returns data. We'll generate dummy daily returns for a hypothetical portfolio.\n",
    "\n",
    "In a new Excel cell, enter `=PY` and paste the following code, then press **Ctrl+Enter**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b386e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy daily returns data for VaR calculation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# Define date range\n",
    "start_date = date(2022, 1, 1)\n",
    "end_date = date(2024, 12, 31)\n",
    "dates = pd.date_range(start=start_date, end=end_date, freq='B') # 'B' frequency for business days\n",
    "\n",
    "# Generate random daily returns (simulating portfolio returns)\n",
    "# Mean return around 0.05% per day, standard deviation 1% per day\n",
    "daily_returns = np.random.normal(loc=0.0005, scale=0.01, size=len(dates))\n",
    "\n",
    "# Create DataFrame\n",
    "df_returns = pd.DataFrame(daily_returns, index=dates, columns=['Portfolio_Daily_Return'])\n",
    "\n",
    "df_returns # Output the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b307487",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "*   This code generates a DataFrame `df_returns` with dummy daily percentage returns for a single portfolio over a few years.\n",
    "*   The returns are simulated using a normal distribution with a small positive mean and a standard deviation typical for daily stock returns.\n",
    "*   The index uses 'B' frequency to simulate business days.\n",
    "*   The result will be spilled into your Excel sheet. Let's assume this data is placed in a range or Table named `PortfolioReturns`.\n",
    "\n",
    "**Step 2: Calculate Value at Risk (VaR)**\n",
    "\n",
    "We will calculate VaR using two common methods:\n",
    "\n",
    "1.  **Historical VaR:** This uses the percentile of the historical return distribution. Simple and doesn't assume a distribution shape.\n",
    "2.  **Parametric VaR:** This assumes the returns follow a normal distribution and uses the mean and standard deviation with a Z-score from the normal distribution (`scipy.stats.norm.ppf`).\n",
    "\n",
    "In a **new** Excel cell, enter `=PY` and paste the following code. Replace `\"PortfolioReturns\"` with the actual name of the Excel range/Table where your dummy returns data is. Press **Ctrl+Enter**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f051e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Historical and Parametric VaR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats # For normal distribution percentile function\n",
    "\n",
    "# Load the daily returns data from Excel\n",
    "# IMPORTANT: Replace \"PortfolioReturns\" with the actual name of your Excel range or Table\n",
    "df_returns_raw = xl(\"PortfolioReturns[#All]\", headers=True)\n",
    "\n",
    "# --- Data Preparation ---\n",
    "\n",
    "# Make a copy and ensure the returns column is numeric\n",
    "df_returns = df_returns_raw.copy()\n",
    "\n",
    "# Assuming the returns are in the second column (index is first)\n",
    "if len(df_returns.columns) < 2:\n",
    "     raise ValueError(\"DataFrame should contain at least two columns: Date and Portfolio Return.\")\n",
    "\n",
    "# Identify the returns column name (assume it's the second column name from the generated data)\n",
    "returns_col_name = df_returns.columns[1]\n",
    "\n",
    "# Convert the returns column to numeric, coercing errors\n",
    "df_returns[returns_col_name] = pd.to_numeric(df_returns[returns_col_name], errors='coerce')\n",
    "\n",
    "# Drop any rows with NaN in the returns column after conversion\n",
    "df_returns.dropna(subset=[returns_col_name], inplace=True)\n",
    "\n",
    "# Check if any data remains\n",
    "if df_returns.empty:\n",
    "     raise ValueError(\"No valid numeric data found in the returns column after cleaning.\")\n",
    "\n",
    "# Extract the numeric returns series\n",
    "portfolio_returns = df_returns[returns_col_name]\n",
    "\n",
    "\n",
    "# --- VaR Calculation ---\n",
    "\n",
    "confidence_level = 0.99 # e.g., 99% confidence\n",
    "alpha = 1 - confidence_level # Significance level (e.g., 0.01 for 99%)\n",
    "\n",
    "# 1. Historical VaR\n",
    "# Calculate the percentile corresponding to the alpha level\n",
    "# The alpha-th percentile of returns is the value such that alpha percent of returns fall below it.\n",
    "# For VaR, we look at the loss side, so we find the 1-confidence_level percentile (e.g., 1st percentile for 99% VaR).\n",
    "# A 1% percentile return of -0.02 means 1% of days lost 2% or more. VaR is reported as a positive loss.\n",
    "historical_var_percentile = portfolio_returns.quantile(alpha)\n",
    "historical_var = -historical_var_percentile # VaR is typically reported as a positive value\n",
    "\n",
    "# 2. Parametric VaR (assuming Normal Distribution)\n",
    "# Calculate the mean and standard deviation of the returns\n",
    "mean_return = portfolio_returns.mean()\n",
    "std_dev_return = portfolio_returns.std()\n",
    "\n",
    "# Find the Z-score for the given confidence level using the Percent Point Function (inverse of CDF)\n",
    "# For 99% confidence, we want the Z-score such that 1% of the area is in the left tail.\n",
    "z_score = stats.norm.ppf(alpha, mean_return, std_dev_return)\n",
    "\n",
    "# Parametric VaR calculation\n",
    "parametric_var = -z_score # VaR is typically reported as a positive value\n",
    "\n",
    "# --- Output ---\n",
    "\n",
    "# Return the calculated VaR values in a dictionary\n",
    "output = {\n",
    "    'Confidence_Level': confidence_level,\n",
    "    'Historical_VaR_Daily': historical_var,\n",
    "    'Parametric_VaR_Daily_Normal_Assumption': parametric_var\n",
    "}\n",
    "\n",
    "output # Output the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9417d8",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "*   We load the dummy daily returns data. **Remember to replace `\"PortfolioReturns\"`**.\n",
    "*   We extract the numeric daily returns column.\n",
    "*   We define the `confidence_level` (e.g., 0.99 for 99%).\n",
    "*   **Historical VaR:** We calculate the value at the `alpha` (1 - confidence level) percentile of the historical returns data using `quantile()`. We negate the result because VaR is reported as a positive loss.\n",
    "*   **Parametric VaR:** We calculate the mean and standard deviation of the returns. We then use `scipy.stats.norm.ppf(alpha, mean, std_dev)` to find the value (the Z-score scaled by mean and std dev) below which `alpha` percentage of returns are expected to fall, assuming a normal distribution. We negate this value for the VaR result.\n",
    "*   We return a dictionary containing the confidence level and the calculated VaR values from both methods.\n",
    "\n",
    "**Viewing the Output:**\n",
    "\n",
    "*   Click the Python cell, then click the Python icon/button next to the formula bar.\n",
    "*   Select \"Excel Value\" (**Ctrl+Shift+Alt+M**) for the dictionary. The individual key-value pairs will spill into adjacent cells, showing the calculated VaR figures.\n",
    "\n",
    "**Further Analysis:**\n",
    "\n",
    "Here are some advanced risk analysis techniques you could explore:\n",
    "\n",
    "1. **Advanced VaR Methods:**\n",
    "   - Implement Expected Shortfall (CVaR)\n",
    "   - Add Monte Carlo VaR simulation\n",
    "   - Create stressed VaR calculations\n",
    "\n",
    "2. **Risk Decomposition:**\n",
    "   - Implement component VaR analysis\n",
    "   - Add factor-based risk decomposition\n",
    "   - Create risk attribution analysis\n",
    "\n",
    "3. **Scenario Analysis:**\n",
    "   - Add historical scenario testing\n",
    "   - Implement stress testing\n",
    "   - Create sensitivity analysis tools\n",
    "\n",
    "4. **Tail Risk Analysis:**\n",
    "   - Calculate extreme value statistics\n",
    "   - Implement copula-based dependency modeling\n",
    "   - Create tail dependence analysis\n",
    "\n",
    "5. **Dynamic Risk Measures:**\n",
    "   - Add dynamic volatility models (GARCH)\n",
    "   - Implement regime-switching models\n",
    "   - Create time-varying correlation analysis\n",
    "\n",
    "This analysis provides a foundation for understanding portfolio risk using VaR. The next major category in the series is [**Business Intelligence - Sales Analytics**](./02-Business%20Intelligence_01-Sales%20Analytics.md), which covers essential techniques for analyzing sales data and identifying trends."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
