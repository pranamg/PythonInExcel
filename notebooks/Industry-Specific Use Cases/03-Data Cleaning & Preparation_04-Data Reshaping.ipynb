{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e19daac",
   "metadata": {},
   "source": [
    "The final topic in the data preparation series is **Data Cleaning & Preparation - 4. Data Reshaping**.\n",
    "\n",
    "Data reshaping is the process of restructuring data layouts between 'wide' and 'long' formats to support different analysis and visualization requirements. The 'wide' format presents categories as separate columns (e.g., monthly sales in distinct columns), while the 'long' format stacks these categories into rows with identifying columns (e.g., separate 'Month' and 'Sales' columns).\n",
    "\n",
    "Based on [`piplist.txt`](./README.md) output, `pandas`, the primary library for these operations (`melt`, `pivot`, `stack`, `unstack`), is available.\n",
    "\n",
    "**Step 1: Generate Sample Data for Reshaping**\n",
    "\n",
    "We'll create two dummy DataFrames:\n",
    "1.  One in a 'wide' format, suitable for converting to 'long' using `melt`.\n",
    "2.  One in a 'long' format, suitable for converting to 'wide' using `pivot_table`.\n",
    "\n",
    "In a new Excel cell, enter `=PY` and paste the following code for the **Wide Data** (e.g., quarterly sales), then press **Ctrl+Enter**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a7b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy Wide Data (e.g., Quarterly Sales)\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "num_regions = 10\n",
    "regions = [fake.state() for _ in range(num_regions)]\n",
    "\n",
    "data = {\n",
    "    'Region': regions,\n",
    "    'Q1_Sales_2023': [random.randint(10000, 50000) for _ in range(num_regions)],\n",
    "    'Q2_Sales_2023': [random.randint(15000, 55000) for _ in range(num_regions)],\n",
    "    'Q3_Sales_2023': [random.randint(20000, 60000) for _ in range(num_regions)],\n",
    "    'Q4_Sales_2023': [random.randint(25000, 65000) for _ in range(num_regions)],\n",
    "    'Q1_Sales_2024': [random.randint(12000, 52000) for _ in range(num_regions)],\n",
    "    'Q2_Sales_2024': [random.randint(18000, 58000) for _ in range(num_regions)],\n",
    "}\n",
    "\n",
    "df_wide = pd.DataFrame(data)\n",
    "\n",
    "df_wide # Output the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4f13d5",
   "metadata": {},
   "source": [
    "Let's assume this data is placed in a range or Table named `QuarterlySalesWide`.\n",
    "\n",
    "In a **separate, new** Excel cell, enter `=PY` and paste the following code for the **Long Data** (e.g., individual survey responses), then press **Ctrl+Enter**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f3180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy Long Data (e.g., Survey Responses)\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "num_respondents = 50\n",
    "questions = ['Service Quality', 'Product Satisfaction', 'Ease of Use', 'Likelihood to Recommend']\n",
    "ratings = [1, 2, 3, 4, 5] # Likert scale\n",
    "\n",
    "data = []\n",
    "for i in range(num_respondents):\n",
    "    respondent_id = f'Resp_{100 + i}'\n",
    "    demographic = random.choice(['Segment A', 'Segment B', 'Segment C'])\n",
    "    for question in questions:\n",
    "        rating = random.choice(ratings)\n",
    "        data.append([respondent_id, demographic, question, rating])\n",
    "\n",
    "df_long = pd.DataFrame(data, columns=['RespondentID', 'Demographic', 'Question', 'Rating'])\n",
    "\n",
    "df_long # Output the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dc670c",
   "metadata": {},
   "source": [
    "Let's assume this data is placed in a range or Table named `SurveyResponsesLong`.\n",
    "\n",
    "**Step 2: Perform Data Reshaping (Melt and Pivot)**\n",
    "\n",
    "Now, we'll load these two dummy DataFrames from Excel and apply reshaping operations. We will 'melt' the `QuarterlySalesWide` data into a long format and 'pivot' the `SurveyResponsesLong` data into a wide format.\n",
    "\n",
    "In a **new** Excel cell, enter `=PY` and paste the following code. Replace `\"QuarterlySalesWide\"` and `\"SurveyResponsesLong\"` with the actual names of the Excel ranges/Tables where your dummy data is. Press **Ctrl+Enter**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704cc445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data reshaping using melt and pivot_table\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the DataFrames from Excel\n",
    "# IMPORTANT: Replace the source names with your actual names\n",
    "df_wide = xl(\"QuarterlySalesWide[#All]\", headers=True)\n",
    "df_long = xl(\"SurveyResponsesLong[#All]\", headers=True)\n",
    "\n",
    "# Ensure data types are appropriate\n",
    "df_wide['Region'] = df_wide['Region'].astype(str)\n",
    "df_long['RespondentID'] = df_long['RespondentID'].astype(str)\n",
    "df_long['Demographic'] = df_long['Demographic'].astype(str)\n",
    "df_long['Question'] = df_long['Question'].astype(str)\n",
    "df_long['Rating'] = pd.to_numeric(df_long['Rating'], errors='coerce')\n",
    "\n",
    "\n",
    "# --- Reshaping Method 1: Melt (Wide to Long) ---\n",
    "# Transform quarterly sales data from columns into rows.\n",
    "# 'Region' is the identifier variable (stays as a column).\n",
    "# The sales columns ('Q1_Sales_2023', etc.) will be \"unpivoted\".\n",
    "# The column names ('Q1_Sales_2023', etc.) will go into a new column named 'Quarter_Year'.\n",
    "# The values (sales figures) will go into a new column named 'Sales'.\n",
    "\n",
    "sales_cols = [col for col in df_wide.columns if 'Sales' in col] # Identify columns to melt\n",
    "\n",
    "df_long_sales = pd.melt(df_wide,\n",
    "                        id_vars=['Region'],       # Columns to keep as identifiers\n",
    "                        value_vars=sales_cols,    # Columns to unpivot\n",
    "                        var_name='Quarter_Year',  # Name for the new column storing old column names\n",
    "                        value_name='Sales')       # Name for the new column storing old values\n",
    "\n",
    "# Optional: Further parse Quarter_Year into separate Quarter and Year columns\n",
    "# Example: Extract 'Q1', '2023'\n",
    "df_long_sales[['Quarter', 'Ignore', 'Year']] = df_long_sales['Quarter_Year'].str.split('_', expand=True)\n",
    "df_long_sales['Year'] = pd.to_numeric(df_long_sales['Year'], errors='coerce') # Convert year to numeric\n",
    "\n",
    "# Drop the original combined column and the 'Ignore' column if they exist\n",
    "df_long_sales = df_long_sales.drop(columns=['Quarter_Year', 'Ignore'], errors='ignore')\n",
    "\n",
    "\n",
    "# --- Reshaping Method 2: Pivot Table (Long to Wide) ---\n",
    "# Transform survey response data to have questions as columns.\n",
    "# 'RespondentID' will be the index (rows).\n",
    "# 'Question' values will become the new columns.\n",
    "# 'Rating' values will fill the cells.\n",
    "# If there are duplicate entries for a RespondentID and Question, pivot_table needs an aggregation function.\n",
    "# Here, we expect one rating per respondent per question, so sum or mean could work, or just rely on default if unique.\n",
    "\n",
    "df_wide_survey = pd.pivot_table(df_long,\n",
    "                                index='RespondentID',   # Column to make the index (rows)\n",
    "                                columns='Question',     # Column whose unique values become new columns\n",
    "                                values='Rating',        # Column whose values fill the new cells\n",
    "                                aggfunc='mean')         # How to handle potential duplicate entries (e.g., average rating)\n",
    "\n",
    "# pivot_table results in a DataFrame with a MultiIndex header for columns if 'columns' has multiple levels.\n",
    "# Here, 'Question' is a single level, so columns are ['Service Quality', 'Product Satisfaction', ...]\n",
    "# The index is 'RespondentID'. You might want to reset index to make RespondentID a regular column.\n",
    "df_wide_survey = df_wide_survey.reset_index()\n",
    "\n",
    "\n",
    "# Output results\n",
    "# Return a dictionary containing the reshaped DataFrames\n",
    "output = {\n",
    "    'Long Sales Data Head (from Wide)': df_long_sales.head(),\n",
    "    'Long Sales Data Shape': pd.DataFrame({'Rows': [df_long_sales.shape[0]], 'Columns': [df_long_sales.shape[1]]}),\n",
    "    'Wide Survey Data Head (from Long)': df_wide_survey.head(),\n",
    "    'Wide Survey Data Shape': pd.DataFrame({'Rows': [df_wide_survey.shape[0]], 'Columns': [df_wide_survey.shape[1]]})\n",
    "}\n",
    "\n",
    "output # Output the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627752d6",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "*   We load the `QuarterlySalesWide` and `SurveyResponsesLong` DataFrames using `xl()`. **Remember to replace the source names.**\n",
    "*   We ensure columns used for merging or values have appropriate data types.\n",
    "*   `pd.melt()`: This function \"unpivots\" a DataFrame from a wide to a long format.\n",
    "    *   `id_vars`: Columns that should remain as identifier variables (e.g., `Region`).\n",
    "    *   `value_vars`: Columns that contain the values you want to stack (e.g., `Q1_Sales_2023`, etc.).\n",
    "    *   `var_name`: The name for the new column that will contain the original column names (`Quarter_Year`).\n",
    "    *   `value_name`: The name for the new column that will contain the values from the original columns (`Sales`).\n",
    "    *   We also added steps to parse the `Quarter_Year` column into separate `Quarter` and `Year` columns for better structure.\n",
    "*   `pd.pivot_table()`: This function creates a spreadsheet-style pivot table as a DataFrame. It aggregates data based on specified index and column values.\n",
    "    *   `index`: The column(s) to form the new DataFrame's index (rows) (e.g., `RespondentID`).\n",
    "    *   `columns`: The column(s) whose unique values will become the new columns (e.g., `Question`).\n",
    "    *   `values`: The column(s) whose values will populate the new DataFrame's cells (e.g., `Rating`).\n",
    "    *   `aggfunc`: The aggregation function to use if there are multiple entries for a given index-column combination (e.g., `mean` to average ratings).\n",
    "    *   `reset_index()` converts the `RespondentID` index back into a regular column.\n",
    "*   We return a dictionary containing the heads and shapes of the resulting reshaped DataFrames.\n",
    "\n",
    "**Viewing the Output:**\n",
    "\n",
    "*   Click the Python cell, then click the Python icon/button next to the formula bar.\n",
    "*   Select \"Excel Value\" (**Ctrl+Shift+Alt+M**) for the DataFrames within the output dictionary to spill them into your sheet. This will show the first few rows and the dimensions of the integrated data.\n",
    "\n",
    "The reshaped data is now optimized for different analytical purposes: the quarterly sales data in 'long' format facilitates time series analysis and quarter-over-quarter comparisons, while the survey data in 'wide' format is ready for customer segmentation or statistical modeling. The next major category is [**Statistical Analysis**](./04-Statistical%20Analysis_01-Descriptive%20Statistics.md), which builds upon these data preparation techniques to derive meaningful insights from the data.\n",
    "\n",
    "**Further Analysis:**\n",
    "* **Multi-Level Reshaping:** Working with hierarchical indices and complex nested data structures using stack/unstack operations\n",
    "* **Dynamic Reshaping:** Implementing automated reshaping based on data structure detection and business rules\n",
    "* **Memory-Efficient Reshaping:** Using chunking and iterative processing for large datasets that exceed memory\n",
    "* **Quality-Aware Reshaping:** Implementing validation checks to ensure data integrity during reshaping operations\n",
    "* **Cross-Tabulation Analysis:** Creating advanced contingency tables with multiple levels of aggregation"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
