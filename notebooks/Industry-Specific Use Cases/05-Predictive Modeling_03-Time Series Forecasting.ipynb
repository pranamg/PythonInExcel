{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf5efa8",
   "metadata": {},
   "source": [
    "**Predictive Modeling - 3. Time Series Forecasting**\n",
    "\n",
    "Time series forecasting helps predict future values using historical time series data. This guide demonstrates using an Exponential Smoothing model from `statsmodels`, with proper handling of the `.predict()` method and explicit index frequency settings.\n",
    "\n",
    "Based on [`piplist.txt`](./README.md) output, you should have `pandas`, `numpy`, `statsmodels`, `seaborn`, and `matplotlib` libraries.\n",
    "\n",
    "**Step 1: Generate Sample Time Series Data for Forecasting**\n",
    "\n",
    "We'll generate a longer daily time series dataset than before, with clear trend and seasonality, to make forecasting meaningful. We'll also include missing values.\n",
    "\n",
    "In a new Excel cell, enter `=PY` and paste the following code, then press **Ctrl+Enter**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d65b74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy daily time series data for forecasting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "import random\n",
    "\n",
    "# Define date range (daily data for several years)\n",
    "start_date = date(2020, 1, 1)\n",
    "end_date = date(2024, 12, 31) # Forecast period included in end date for generating data\n",
    "dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "n_points = len(dates)\n",
    "\n",
    "# Simulate components:\n",
    "# 1. Trend: Linear trend with a slight curve\n",
    "trend = np.linspace(100, 500, n_points) + np.sin(np.linspace(0, np.pi, n_points)) * 50\n",
    "\n",
    "# 2. Seasonality: Weekly pattern (e.g., higher values on weekends)\n",
    "day_of_week = dates.dayofweek.values\n",
    "weekly_seasonality = np.sin(day_of_week * (2 * np.pi / 7)) * 30\n",
    "weekly_seasonality[day_of_week >= 5] += 25 # Boost weekends\n",
    "\n",
    "# 3. Longer-term Seasonality (e.g., yearly pattern, simplified)\n",
    "yearly_seasonality = np.sin(dates.dayofyear * (2 * np.pi / 365.25)) * 40\n",
    "\n",
    "# 4. Noise: Random fluctuations\n",
    "noise = np.random.normal(0, 20, n_points) # Mean 0, Std Dev 20\n",
    "\n",
    "# Combine components (additive model)\n",
    "value = trend + weekly_seasonality + yearly_seasonality + noise\n",
    "\n",
    "# Ensure values are non-negative\n",
    "value = np.maximum(20, value) # Floor at 20\n",
    "\n",
    "# Create DataFrame\n",
    "df_ts_forecast = pd.DataFrame({'Date': dates, 'Value': value.round(2)})\n",
    "\n",
    "# Add some missing values randomly\n",
    "missing_indices = random.sample(range(n_points), int(n_points * 0.05)) # 5% missing\n",
    "df_ts_forecast.loc[missing_indices, 'Value'] = np.nan\n",
    "\n",
    "\n",
    "df_ts_forecast # Output the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d88776",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "*   This code generates a DataFrame `df_ts_forecast` with daily data, incorporating trend, weekly, and a simplified yearly seasonality, plus noise.\n",
    "*   The date range extends into 2024 to provide a period for forecasting.\n",
    "*   Missing values (`np.nan`) are added to the `Value` column.\n",
    "*   The result, `df_ts_forecast`, will be spilled into your Excel sheet. Let's assume this data is placed in a range or Table named `ForecastData`.\n",
    "\n",
    "**Step 2: Prepare Data, Build, Forecast, and Evaluate Time Series Model**\n",
    "\n",
    "Now, we'll load this dummy data, set the index frequency explicitly, handle missing values, split the data chronologically, train an `ExponentialSmoothing` model, use `.predict()` for forecasting, evaluate the forecasts, and visualize the results.\n",
    "\n",
    "In a **new** Excel cell, enter `=PY` and paste the following code. Replace `\"ForecastData\"` with the actual name of the Excel range/Table where your dummy data is. Press **Ctrl+Enter**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bfde9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data, build, forecast, and evaluate Time Series model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing # For forecasting\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error # For evaluation\n",
    "import warnings\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# Suppress specific statsmodels warnings that can occur with fitting\n",
    "warnings.filterwarnings(\"ignore\", message=\"OptimizationWarning:\")\n",
    "\n",
    "\n",
    "# Load the data from Excel\n",
    "# IMPORTANT: Replace \"ForecastData\" with the actual name of your Excel range or Table\n",
    "df = xl(\"ForecastData[#All]\", headers=True)\n",
    "\n",
    "# Ensure 'Date' is a datetime column and set it as the index\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.set_index('Date')\n",
    "\n",
    "# Ensure the index is sorted (important for time series)\n",
    "df = df.sort_index()\n",
    "\n",
    "# --- Data Preparation ---\n",
    "\n",
    "# Explicitly set the frequency of the index as requested\n",
    "# This is crucial for statsmodels models that expect a regular frequency\n",
    "# 'D' stands for daily frequency\n",
    "# If your original data source might skip dates, asfreq('D') will add them with NaNs\n",
    "df = df.asfreq('D')\n",
    "print(f\"DataFrame index frequency set to: {df.index.freq}\") # Print freq for confirmation\n",
    "\n",
    "# Handle missing values in the time series data BEFORE fitting the model\n",
    "# Interpolation is a common method for time series NaNs\n",
    "df['Value'] = df['Value'].interpolate(method='time') # Use time-based interpolation\n",
    "\n",
    "# Check if there are still NaNs (e.g., at the very beginning or end if interpolate can't fill)\n",
    "if df['Value'].isnull().sum() > 0:\n",
    "     print(f\"Warning: {df['Value'].isnull().sum()} NaNs remaining after interpolation. Filling remaining with median.\")\n",
    "     df['Value'] = df['Value'].fillna(df['Value'].median()) # Fallback fill\n",
    "\n",
    "\n",
    "# Define the split point for training and testing (e.g., last 6 months for test)\n",
    "forecast_period_days = 180 # Forecast for ~6 months\n",
    "train_end_date = df.index.max() - timedelta(days=forecast_period_days)\n",
    "\n",
    "# Split data chronologically\n",
    "train_data = df.loc[df.index <= train_end_date, 'Value']\n",
    "test_data = df.loc[df.index > train_end_date, 'Value']\n",
    "\n",
    "print(f\"Training data ends on: {train_data.index.max().date()}\")\n",
    "print(f\"Testing data starts on: {test_data.index.min().date()}\")\n",
    "\n",
    "\n",
    "# --- Model Training (Exponential Smoothing) ---\n",
    "# Choose model parameters: trend ('add' or 'mul'), seasonal ('add' or 'mul'), seasonal_periods\n",
    "# Our simulated data has additive trend and additive weekly seasonality (period=7)\n",
    "# Using SimpleExpSmoothing would only handle level, Holt's handles trend, Holt-Winters handles trend and seasonality\n",
    "# ExponentialSmoothing is the flexible model\n",
    "model = ExponentialSmoothing(train_data,\n",
    "                             trend='add',           # Additive trend\n",
    "                             seasonal='add',        # Additive seasonality\n",
    "                             seasonal_periods=7)    # Weekly seasonality for daily data\n",
    "\n",
    "# Fit the model\n",
    "# Use optimize_errors='add' for additive model fitting optimization\n",
    "fitted_model = model.fit(optimized=True, remove_bias=False) # Optimized=True finds best parameters\n",
    "\n",
    "\n",
    "# --- Forecasting using .predict() ---\n",
    "# Generate forecasts for the test period using the .predict() method on the fitted model\n",
    "# Pass the start and end *dates* (or indices) for the forecast period\n",
    "forecast_start_date = test_data.index.min()\n",
    "forecast_end_date = test_data.index.max()\n",
    "\n",
    "# The .predict() method when used on the *fitted model* (`fitted_model`) with specified dates\n",
    "# generates the out-of-sample forecast.\n",
    "forecast_values = fitted_model.predict(start=forecast_start_date, end=forecast_end_date)\n",
    "\n",
    "\n",
    "# --- Model Evaluation ---\n",
    "# Evaluate forecasts against actual values in the test set\n",
    "# Align test data and forecast data index in case of slight date mismatches (though asfreq helps)\n",
    "actual_test_values = test_data.reindex(forecast_values.index).dropna()\n",
    "predicted_forecast_values = forecast_values.reindex(actual_test_values.index)\n",
    "\n",
    "\n",
    "if len(actual_test_values) > 0:\n",
    "    mae = mean_absolute_error(actual_test_values, predicted_forecast_values)\n",
    "    mse = mean_squared_error(actual_test_values, predicted_forecast_values)\n",
    "    rmse = np.sqrt(mse) # Root Mean Squared Error\n",
    "\n",
    "    evaluation_metrics = pd.DataFrame({\n",
    "        'Metric': ['Mean Absolute Error (MAE)', 'Mean Squared Error (MSE)', 'Root Mean Squared Error (RMSE)'],\n",
    "        'Value': [mae, mse, rmse]\n",
    "    })\n",
    "else:\n",
    "    evaluation_metrics = pd.DataFrame({'Result': [\"Not enough data in the test set to evaluate forecasts.\"]})\n",
    "\n",
    "\n",
    "# --- Visualization ---\n",
    "\n",
    "# Apply custom style guidelines\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.edgecolor'] = '#1a1a24'\n",
    "plt.rcParams['axes.linewidth'] = 1\n",
    "plt.rcParams['axes.grid'] = False # Turn off default grid\n",
    "sns.set_theme(style=\"whitegrid\") # Use a seaborn theme base, then apply customs\n",
    "\n",
    "\n",
    "# Plot training data, actual test data, and forecasts\n",
    "fig1, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Plot training data\n",
    "ax1.plot(train_data.index, train_data, label='Training Data', color='#1a1a24', linewidth=1) # Off-black\n",
    "\n",
    "# Plot actual test data\n",
    "ax1.plot(test_data.index, test_data, label='Actual Test Data', color='#188ce5', linewidth=1.5) # Blue\n",
    "\n",
    "# Plot forecasted values\n",
    "ax1.plot(forecast_values.index, forecast_values, label='Forecast', color='#ff6d00', linewidth=1.5, linestyle='--') # Orange dashed\n",
    "\n",
    "ax1.set_title('Time Series Forecasting (Exponential Smoothing)', fontsize=14, color='#1a1a24')\n",
    "ax1.set_xlabel('Date', fontsize=12, color='#1a1a24')\n",
    "ax1.set_ylabel('Value', fontsize=12, color='#1a1a24')\n",
    "ax1.legend()\n",
    "sns.despine(ax=ax1, top=True, right=True)\n",
    "ax1.grid(False)\n",
    "fig1.autofmt_xdate() # Auto-format date labels\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Output results\n",
    "# Return a dictionary containing evaluation metrics and the plot\n",
    "output = {\n",
    "    'Forecast Evaluation Metrics': evaluation_metrics,\n",
    "    'Forecast Values Head': forecast_values.head(), # Show head of forecast series\n",
    "    'Actual Test Values Head': actual_test_values.head(), # Show head of actual test series\n",
    "    'Time_Series_Forecast_Plot': fig1\n",
    "}\n",
    "\n",
    "output # Output the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a853ef",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "*   We load the dummy time series data. **Remember to replace `\"ForecastData\"`**.\n",
    "*   We convert the 'Date' column to datetime and set it as the DataFrame index.\n",
    "*   We sort the index to ensure the time series is in chronological order.\n",
    "*   **Explicitly set Frequency:** `df = df.asfreq('D')` is used to explicitly set the index frequency to daily ('D'). If the original data missed any dates, `asfreq` inserts them with `NaN` values, making the index regular as required by many time series models.\n",
    "*   **Handle Missing Values:** `df['Value'].interpolate(method='time')` fills `NaN`s using time-weighted linear interpolation, suitable for time series data. A fallback `fillna` is included in case interpolation fails (e.g., at the very start).\n",
    "*   **Data Splitting:** The data is split into a training set (up to a defined date) and a testing/forecast set (the period after that date). This simulates training on historical data and forecasting/evaluating on unseen future data.\n",
    "*   **Model Training:** `statsmodels.tsa.holtwinters.ExponentialSmoothing` is initialized. We specify `trend='add'` and `seasonal='add'` based on our simulated data's properties, and `seasonal_periods=7` for daily data with weekly seasonality. `.fit()` trains the model on the `train_data`.\n",
    "*   **Forecasting with `.predict()`:** **As requested**, we use the `.predict()` method of the *fitted model object* (`fitted_model`) and provide the `start` and `end` dates corresponding to the `test_data` index. This correctly generates out-of-sample forecasts for the specified period.\n",
    "*   **Model Evaluation:** We calculate `Mean Absolute Error (MAE)` and `Root Mean Squared Error (RMSE)` by comparing the `forecast_values` to the `actual_test_values`. These metrics quantify the average forecast error. We use `reindex` and `dropna` to ensure perfect alignment between the forecast and actual values for evaluation.\n",
    "*   **Visualization:** A plot shows the original training data, the actual values in the test period, and the predicted forecast values. This visually assesses how well the forecast aligns with the actual future data.\n",
    "*   **Custom Style:** Applied the specified style guidelines (font, colors - off-black for training data, blue for actual test data, orange dashed for forecast, off-black for text/axes, axes, spines, grid, formatted x-axis for dates).\n",
    "*   We return a dictionary containing DataFrames for the evaluation metrics and heads of the forecast/actual test Series, and the forecast plot figure.\n",
    "\n",
    "**Viewing the Output:**\n",
    "\n",
    "*   Click the Python cell, then click the Python icon/button next to the formula bar.\n",
    "*   Select \"Excel Value\" (**Ctrl+Shift+Alt+M**) for the DataFrames/Series ('Forecast Evaluation Metrics', 'Forecast Values Head', 'Actual Test Values Head') to spill them into your sheet.\n",
    "*   For the plot figure object ('Time_Series_Forecast_Plot'), select \"Picture in Cell\" > \"Create Reference\" to see the plot.\n",
    "\n",
    "This demonstrates how to build and evaluate a basic time series forecasting model using `statsmodels` and the `.predict()` method.\n",
    "\n",
    "**Further Analysis:**\n",
    "\n",
    "Here are some advanced analyses you could perform on this time series dataset:\n",
    "\n",
    "1. **Advanced Forecasting Models:**\n",
    "   - Implement SARIMA (Seasonal ARIMA) models for complex seasonality patterns\n",
    "   - Use Prophet for automatic handling of holidays and multiple seasonal patterns\n",
    "   - Apply LSTM or other deep learning models for non-linear time series patterns\n",
    "\n",
    "2. **Multi-variate Time Series Analysis:**\n",
    "   - Include external regressors (e.g., weather data, economic indicators)\n",
    "   - Implement VAR (Vector Autoregression) models\n",
    "   - Study cross-correlations between multiple time series\n",
    "\n",
    "3. **Anomaly Detection:**\n",
    "   - Implement statistical process control charts\n",
    "   - Use isolation forests or other ML-based anomaly detection\n",
    "   - Develop real-time monitoring systems\n",
    "\n",
    "4. **Decomposition Analysis:**\n",
    "   - Compare different decomposition methods (additive vs. multiplicative)\n",
    "   - Study trend-cycle separation techniques\n",
    "   - Analyze multiple seasonal patterns at different frequencies\n",
    "\n",
    "5. **Forecasting Performance Analysis:**\n",
    "   - Implement rolling-window cross-validation\n",
    "   - Compare different error metrics (MAPE, RMSE, MAE)\n",
    "   - Study forecast uncertainty using prediction intervals\n",
    "\n",
    "The next topic in the series is [Visualization - Basic Plots (Line, Bar, Scatter)](./06-Visualization_01-Basic%20Plots%20(Line,Bar,Scatter).md), which explores fundamental data visualization techniques using Python plotting libraries.\n",
    "\n",
    "This completes the Time Series Forecasting section. The next category covers **Visualization**, where you'll learn to create various types of visual representations of your data. For additional practice, try implementing different time series models or refining the forecasting approach with your own data."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
